{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    %pip install patchright lxml nest_asyncio\n",
    "    !playwright install\n",
    "    !patchright install chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Dict, List\n",
    "from patchright.async_api import async_playwright\n",
    "from lxml import html\n",
    "import asyncio\n",
    "from abc import ABC, abstractmethod\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scroll_to_bottom(page, scroll_delay=0.1):\n",
    "    \"\"\"\n",
    "    Scroll to the bottom of the page iteratively, with delays to ensure dynamic content is fully loaded.\n",
    "    \n",
    "    Args:\n",
    "        page: The Playwright page instance.\n",
    "        scroll_delay: Delay in seconds between scrolls to allow content loading.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Scrolling through the page...\")\n",
    "    \n",
    "    scroll_size = 2160\n",
    "\n",
    "    next_scroll = scroll_size\n",
    "    for i in range(3):\n",
    "        # Scroll 500 pixels at a time\n",
    "        await page.evaluate(f\"window.scrollTo(0, {next_scroll})\")\n",
    "\n",
    "        next_scroll += scroll_size\n",
    "\n",
    "        # Wait for content to load\n",
    "        await asyncio.sleep(scroll_delay)\n",
    "        \n",
    "    print(\"Finished scrolling through the page.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def block_unnecessary_resources(route):\n",
    "    if route.request.resource_type in [\"image\"]:\n",
    "        await route.abort()\n",
    "    else:\n",
    "        await route.continue_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebsiteInterface(ABC):\n",
    "    def __init__(self):\n",
    "        self.base_url = \"\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    async def crawl(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Abstract method to crawl the website and extract listings.\n",
    "        Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_filters_info(self) -> str:\n",
    "        \"\"\"\n",
    "        Abstract method to return a prompt for the LLM describing the filters and expected output format.\n",
    "        Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_filters_from_llm_response(self, llm_response: str):\n",
    "        \"\"\"\n",
    "        Abstract method to process the LLM's response and set the URL with appropriate filters.\n",
    "        Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class AutotraderInterface(WebsiteInterface):\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.autotrader.com/cars-for-sale/all-cars\"\n",
    "        # https://www.autotrader.com/cars-for-sale/all-cars/floral-park-ny?endYear=2022&makeCode=BMW&makeCode=FORD&newSearch=true&startYear=2012&zip=11001\n",
    "        \n",
    "    async def crawl(self) -> List[Dict[str, str]]:\n",
    "        listings = []\n",
    "        \n",
    "        url = self.url\n",
    "\n",
    "        playwright = await async_playwright().start()\n",
    "\n",
    "        # Launch browser in headless mode\n",
    "        browser = await playwright.chromium.launch(headless=True,\n",
    "                                                    args=[\n",
    "                                                            \"--no-sandbox\",\n",
    "                                                            \"--disable-setuid-sandbox\",\n",
    "                                                            \"--disable-dev-shm-usage\",\n",
    "                                                            \"--disable-extensions\",\n",
    "                                                            \"--disable-gpu\"\n",
    "                                                    ]\n",
    "                                                    )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "            viewport={\"width\": 1920, \"height\": 1080},\n",
    "            # no_viewport=True\n",
    "            locale=\"en-US\",\n",
    "            timezone_id=\"America/New_York\",\n",
    "            # java_script_enabled=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\"Opening browser page\")\n",
    "\n",
    "        page = await context.new_page()\n",
    "        \n",
    "        await page.route(\"**/*\", block_unnecessary_resources)\n",
    "\n",
    "        print(\"Loading page\")\n",
    "        \n",
    "        await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "\n",
    "        print(\"Page partially loaded. Starting to scroll.\")\n",
    "\n",
    "        # Print text of the page\n",
    "        # print(await page.content())\n",
    "        \n",
    "        # If \"This site asks for consent to use your data\" is present in the page, click on \"Consent\" button with class \"fc-button fc-cta-consent fc-primary-button\"\n",
    "        # print(\"Accepting cookies\")\n",
    "        # try:\n",
    "        #     page.click('text=\"Consent\"', timeout=30000)\n",
    "        #     print(\"Cookies accepted\")\n",
    "        # except:\n",
    "        #     print(\"No cookies to accept\")\n",
    "        \n",
    "        # Scroll to the bottom of the page\n",
    "        await scroll_to_bottom(page)\n",
    "        \n",
    "        page_content = await page.content()\n",
    "        \n",
    "        # Parse HTML using lxml\n",
    "        tree = html.fromstring(page_content)\n",
    "\n",
    "        # XPath to select each car listing container\n",
    "        listings_elements = tree.xpath('//div[@data-cmp=\"inventoryListing\"]')\n",
    "\n",
    "        listings = []\n",
    "\n",
    "        for listing in listings_elements:\n",
    "            car_data = {}\n",
    "            # Extract car details\n",
    "            car_data['title'] = listing.xpath('.//h2[@data-cmp=\"subheading\"]/text()')\n",
    "            car_data['mileage'] = listing.xpath('.//div[@data-cmp=\"mileageSpecification\"]/text()')\n",
    "            car_data['price'] = listing.xpath('.//div[@data-cmp=\"firstPrice\"]/text()')\n",
    "            car_data['dealer'] = listing.xpath('.//div[@class=\"text-subdued\"]/text()')\n",
    "            car_data['phone'] = listing.xpath('.//span[@data-cmp=\"phoneNumber\"]/text()')\n",
    "            car_data['url'] = listing.xpath('.//a[@data-cmp=\"link\"]/@href')\n",
    "            car_data['image'] = listing.xpath('.//img[@data-cmp=\"inventoryImage\"]/@src')\n",
    "            \n",
    "            # Clean up extracted data\n",
    "            car_data = {key: (val[0].strip() if val else None) for key, val in car_data.items()}\n",
    "            \n",
    "            car_data['url'] = car_data['url'].split('?')[0]\n",
    "            \n",
    "            # Add domain to the URL. Extract domain from the base URL without the path\n",
    "            car_data['url'] = re.sub(r'^(https?://[^/]+).*$', r'\\1', self.base_url) + car_data['url']\n",
    "            \n",
    "            # Set the ID of the listing as the ID of the WebsiteInterface and the car number from URL\n",
    "            car_data = { \"id\": f\"{self.__class__.__name__}_{car_data['url'].split('/')[-1]}\" } | car_data\n",
    "            \n",
    "            listings.append(car_data)\n",
    "            \n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"Found the following car listings:\")\n",
    "            # Display the extracted data\n",
    "            for car in listings:\n",
    "                print(car)\n",
    "\n",
    "        print(\"Found\", len(listings), \"listings\")\n",
    "\n",
    "        await browser.close()\n",
    "        \n",
    "        return listings\n",
    "    \n",
    "    async def crawl_listing(self, listing_url) -> List[Dict[str, str]]:\n",
    "        listing_info = \"\"\n",
    "        \n",
    "        url = listing_url\n",
    "\n",
    "        playwright = await async_playwright().start()\n",
    "\n",
    "        # Launch browser in headless mode\n",
    "        browser = await playwright.chromium.launch(headless=True,\n",
    "                                                    args=[\n",
    "                                                            \"--no-sandbox\",\n",
    "                                                            \"--disable-setuid-sandbox\",\n",
    "                                                            \"--disable-dev-shm-usage\",\n",
    "                                                            \"--disable-extensions\",\n",
    "                                                            \"--disable-gpu\"\n",
    "                                                    ]\n",
    "                                                    )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "            viewport={\"width\": 1920, \"height\": 1080},\n",
    "            # no_viewport=True\n",
    "            locale=\"en-US\",\n",
    "            timezone_id=\"America/New_York\",\n",
    "            # java_script_enabled=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\"Opening browser page\")\n",
    "\n",
    "        page = await context.new_page()\n",
    "        \n",
    "        await page.route(\"**/*\", block_unnecessary_resources)\n",
    "\n",
    "        print(\"Loading page\")\n",
    "        \n",
    "        await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "\n",
    "        print(\"Page partially loaded. Starting to scroll.\")\n",
    "\n",
    "        # Scroll to the bottom of the page\n",
    "        await scroll_to_bottom(page)\n",
    "\n",
    "        # Get full HTML\n",
    "        page_content = await page.content()\n",
    "\n",
    "        # Parse HTML using lxml to extract all the text\n",
    "        tree = html.fromstring(page_content)\n",
    "        listing_info = tree.xpath(\"//div[contains(@class, 'container') and contains(@class, 'margin-top-5')]/div[contains(@class, 'row')]//text()\")\n",
    "        listing_info = \"\\t\".join(listing_info).strip()\n",
    "\n",
    "        # Seller information should already be included in the listing information\n",
    "        # seller_info = tree.xpath(\"//div[@id='sellerComments']//text()\")\n",
    "        # listing_info = listing_info + seller_info\n",
    "            \n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"Found the following information:\")\n",
    "            # Print the extracted text\n",
    "            print(listing_info)\n",
    "\n",
    "        await browser.close()\n",
    "        \n",
    "        return listing_info\n",
    "    \n",
    "    def get_filters_info(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a prompt for the LLM describing the filters and expected output format.\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "        You are a helpful assistant that translates user requirements into a URL with query parameters.\n",
    "\n",
    "        The base URL is: {self.base_url}\n",
    "        Filters:\n",
    "        - zip: User's zip code (integer).\n",
    "        - searchRadius: Search radius in miles (integer, e.g., 75, 100, 200).\n",
    "        - startYear: Minimum year of the car (integer).\n",
    "        - endYear: Maximum year of the car (integer).\n",
    "        - makeCode: Car manufacturer code (string, can appear multiple times, e.g., \"BMW\", \"FORD\").\n",
    "        - listingType: Type of listing (one of \"NEW\", \"USED\", \"CERTIFIED\", \"3P_CERT\").\n",
    "        - mileage: Maximum mileage of the car (integer).\n",
    "        - driveGroup: Type of drive (one of \"AWD4WD\", \"FWD\", \"RWD\").\n",
    "        - extColorSimple: External color of the car (e.g., \"BLACK\", \"WHITE\", \"RED\", \"GRAY\").\n",
    "        - intColorSimple: Internal color of the car (e.g., \"BEIGE\", \"BLACK\", \"BLUE\").\n",
    "        - mpgRange: Fuel efficiency in miles per gallon (e.g., \"30-MPG\").\n",
    "        - fuelTypeGroup: Type of fuel (one of \"GSL\", \"DSL\", \"HYB\", \"ELE\", \"PIH\").\n",
    "        - bodyStyleSubtypeCode: Type of body style (e.g., \"FULLSIZE_CREW\", \"COMPACT_EXTEND\").\n",
    "        - truckBedLength: Truck bed length (e.g., \"SHORT\", \"EXTRA SHORT\", \"UNSPECIFIED\").\n",
    "        - vehicleStyleCode: Vehicle style (e.g., \"CONVERT\", \"WAGON\", \"HATCH\", \"SUVCROSS\").\n",
    "        - dealType: Type of deal (e.g., \"goodprice\", \"greatprice\").\n",
    "        - doorCode: Number of doors (e.g., \"2\", \"3\", \"4\").\n",
    "        - engineDisplacement: Engine size range in liters (e.g., \"1.0-1.9\", \"2.0-2.9\").\n",
    "        - featureCode: Specific features of the car (e.g., \"1062\" for heated seats, \"1327\" for navigation).\n",
    "        - transmissionCode: Transmission type (e.g., \"AUT\" for automatic, \"MAN\" for manual).\n",
    "        - vehicleHistoryType: Vehicle history (e.g., \"NO_ACCIDENTS\", \"ONE_OWNER\", \"CLEAN_TITLE\").\n",
    "        - newSearch: Boolean to indicate a new search (e.g., \"true\").\n",
    "        - sortBy: Sorting option for the results (optional). \n",
    "            Options:\n",
    "            - \"relevance\" (default): Sort by relevance.\n",
    "            - \"derivedpriceASC\": Sort by price, lowest to highest.\n",
    "            - \"derivedpriceDESC\": Sort by price, highest to lowest.\n",
    "            - \"distanceASC\": Sort by distance, closest to farthest.\n",
    "            - \"datelistedASC\": Sort by date, oldest first.\n",
    "            - \"datelistedDESC\": Sort by date, newest first.\n",
    "            - \"mileageASC\": Sort by mileage, lowest to highest.\n",
    "            - \"mileageDESC\": Sort by mileage, highest to lowest.\n",
    "            - \"yearASC\": Sort by year, oldest to newest.\n",
    "            - \"yearDESC\": Sort by year, newest to oldest.\n",
    "        \n",
    "        Special filters:\n",
    "        - price: Price is embedded in the path of the URL, e.g., \"/cars-over-45000\" or \"/cars-between-10000-and-20000\".\n",
    "\n",
    "        Example Output:\n",
    "        A complete URL with query parameters, e.g.,:\n",
    "        \"{self.base_url}/cars-between-10000-and-20000?zip=10001&startYear=2010&endYear=2020&makeCode=BMW&makeCode=FORD&listingType=USED&mileage=50000&fuelTypeGroup=GSL&intColorSimple=BLACK&vehicleHistoryType=NO_ACCIDENTS\"\n",
    "\n",
    "        Based on the user's needs, format the response as only the complete URL (no extra explanations). The URL is an example, don't include filters if they are not needed by the user.\n",
    "        \"\"\"\n",
    "        \n",
    "    def set_filters_from_llm_response(self, llm_response: str):\n",
    "        \"\"\"\n",
    "        Process the LLM's response and set the URL with the provided parameters.\n",
    "        \"\"\"\n",
    "        # Validate and set the URL from LLM's response\n",
    "        if llm_response.startswith(self.base_url):\n",
    "            self.url = llm_response.strip()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid URL format provided by LLM response: \" + llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     interface = AutotraderInterface()\n",
    "#     interface.url = \"https://www.autotrader.com/cars-for-sale/all-cars/cars-under-10000?newSearch=true&bodyStyleSubtypeCode=COMPACT&mpgRange=30-MPG&vehicleHistoryType=CLEAN_TITLE\"\n",
    "\n",
    "#     listings = await interface.crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     interface = AutotraderInterface()\n",
    "#     listing_info = await interface.crawl_listing(\"https://www.autotrader.com/cars-for-sale/vehicle?listingId=726641083&clickType=elot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
