{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26bdf70-b1db-4a22-acf3-ee0391c21772",
   "metadata": {},
   "source": [
    "# Memory: A Deep Dive: Practical Implementation (Self Healing Codebase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a4cd9-ae03-4a15-b1e8-2ef1ab15770a",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This code implements a workflow-based error detection and correction system that combines LangGraph and LLM capabilities to detect runtime errors, generate fixes, and maintain a memory of bug patterns. The system takes function definitions and runtime arguments, processes them through a graph-based workflow, and maintains a hierarchical error management system (error → analysis → fix → validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b07f7-837a-484b-9c30-5c52c9d7df98",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Several key factors motivate this implementation:\n",
    "\n",
    "1. **Automated Error Resolution**\n",
    "   - Manual debugging is time-consuming and error-prone\n",
    "   - Automated fix generation streamlines the correction process\n",
    "   - LLMs can provide context-aware code repairs\n",
    "\n",
    "2. **Stateful Error Management**\n",
    "   - Need for systems that track error correction workflow\n",
    "   - Importance of maintaining error context\n",
    "   - Value of tracking fix attempts\n",
    "\n",
    "3. **Structured Bug Knowledge**\n",
    "   - Need for consistent error pattern recognition\n",
    "   - Importance of maintaining fix history\n",
    "   - Benefits of hierarchical error categorization\n",
    "\n",
    "4. **Runtime Code Modification**\n",
    "   - Recognition that code fixes need controlled deployment\n",
    "   - Value of state tracking during modifications\n",
    "   - Importance of safe runtime patching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d550fa8-889d-4b28-9b2a-6fcdc5fef755",
   "metadata": {},
   "source": [
    "## Key Components\n",
    "1. **State Management System**: \n",
    "   - Maintains workflow state using Pydantic models\n",
    "   - Tracks function references, errors, and fixes\n",
    "   - Ensures type safety and execution validation\n",
    "\n",
    "2. **LLM Integration**: \n",
    "   - Leverages LLM for code analysis and generation\n",
    "   - Produces fixes based on error types:\n",
    "     - Runtime Errors\n",
    "     - Logic Errors\n",
    "     - Type Errors\n",
    "     - Resource Errors\n",
    "\n",
    "3. **Graph-based Workflow**: \n",
    "   - Uses LangGraph's StateGraph for orchestration\n",
    "   - Implements error detection nodes\n",
    "   - Controls fix generation through edges\n",
    "\n",
    "4. **Memory Structure**:\n",
    "   - Follows error pattern organization\n",
    "   - Maintains context with each fix\n",
    "   - Supports multiple error categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b3700-fb63-4d15-b740-9643210a4bc8",
   "metadata": {},
   "source": [
    "## Visual Overview\n",
    "A flowchart representing the design and flow of the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114383f-c940-4b69-bc90-9912161ca0e7",
   "metadata": {},
   "source": [
    "<div style=\"max-width:600px;\">\n",
    "    \n",
    "![image.png](../images/self_healing_code.png)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf758b1-e1c3-499b-bf29-b51264d8d0be",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This implementation demonstrates a practical approach to automated code healing. The system combines graph-based workflow management with LLM capabilities, allowing for structured error correction while maintaining clear process control.\n",
    "\n",
    "Key advantages include:\n",
    "- Automated error detection and correction\n",
    "- Clear state management\n",
    "- Pattern-based fix generation\n",
    "- Safe runtime code modification\n",
    "\n",
    "Future improvements could focus on:\n",
    "- Enhanced fix validation\n",
    "- Multiple fix generation\n",
    "- State persistence strategies\n",
    "- Memory optimization techniques\n",
    "\n",
    "This system provides a foundation for building more sophisticated self-healing systems, particularly in applications requiring runtime error correction and pattern learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01726055-58e2-42f0-953d-50a58ef25544",
   "metadata": {},
   "source": [
    "# Dependencies and Imports\n",
    "Install dependencies and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6a6ae2-8687-4c70-82a7-34959555dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install langgraph\n",
    "!pip install langgraph-sdk\n",
    "!pip install langgraph-checkpoint-sqlite\n",
    "!pip install langchain-community\n",
    "!pip install langchain-core\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a851309b-b375-481d-bc58-f3fc314a1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import json\n",
    "import os\n",
    "import types\n",
    "import inspect\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405fcf49-c87e-46e2-a3fc-1c8fde6d25fa",
   "metadata": {},
   "source": [
    "## Clients\n",
    "Import API keys and instantiate clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb54e70c-cc2e-4907-a240-758b2540f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'YOUR-API-KEY'\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83900a95-a236-471b-bcc0-02d61b887b3b",
   "metadata": {},
   "source": [
    "## Define Agent State\n",
    "We'll define the state that our agent will maintain throughout its operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de61661-51b0-4ad3-b6f5-f3caa168d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    function: Callable\n",
    "    function_string: str\n",
    "    arguments: list\n",
    "    error: bool\n",
    "    error_description: str = ''\n",
    "    new_function_string: str = ''\n",
    "    bug_report: str = ''\n",
    "    memories: list = []\n",
    "    memory_indexes_to_update: list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35c846-3b39-42b8-9d51-b6c14d7de716",
   "metadata": {},
   "source": [
    "## Define Code Healing Node Functions\n",
    "Now we'll define the code healing node functions that our agent will use: run_code, update_code and fix_code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596ffc4a-bb83-45ae-8ab8-e162bb566af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code(state: State):\n",
    "    ''' Run Arbitrary Code '''\n",
    "    try:\n",
    "        result = state.function(*state.arguments)\n",
    "    except Exception as e:\n",
    "        state.error = True\n",
    "        state.error_description = str(e)\n",
    "    return state\n",
    "\n",
    "\n",
    "def update_code(state: State):\n",
    "    ''' Update Arbitratry Code '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with fixing a Python function that raised an error.'\n",
    "        'Function: {function_string}'\n",
    "        'Error: {error_description}' \n",
    "        'You must provide a fix for the present error only.'\n",
    "        'The bug fix should handle the thrown error case gracefully by returning an error message.'\n",
    "        'Do not raise an error in your bug fix.'\n",
    "        'The function must use the exact same name and parameters.'\n",
    "        'Your response must contain only the function definition with no additional text.'\n",
    "        'Your response must not contain any additional formatting, such as code delimiters or language declarations.'\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
    "    new_function_string = llm.invoke([message]).content.strip()\n",
    "\n",
    "    state.new_function_string = new_function_string\n",
    "    return state\n",
    "\n",
    "\n",
    "def fix_code(state: State):\n",
    "    ''' Fix Arbitrary Code '''\n",
    "    try:        \n",
    "        # Store the new function as a string\n",
    "        new_code = state.new_function_string\n",
    "        \n",
    "        # Create namespace for new function\n",
    "        namespace = {}\n",
    "        \n",
    "        # Execute new code in namespace\n",
    "        exec(new_code, namespace)\n",
    "        \n",
    "        # Get the new function\n",
    "        new_divide = namespace['divide_two_numbers']\n",
    "        \n",
    "        # Update state\n",
    "        state.function = new_divide\n",
    "        state.error = False\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f'Update failed: {e}')\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747892fd-9e10-490b-a0ee-d8aadb2eebb0",
   "metadata": {},
   "source": [
    "## Define Bug Reporting Node Functions\n",
    "Now we'll define the bug reporting node functions that our agent will use: bug_report_node, memory_search_node, memory_generation_node and memory_modification_node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4d829b-ec81-425a-a38c-819b63c1fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_report_node(state: State):\n",
    "    ''' Generate Bug Report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with generating a bug report for a Python function that raised an error.'\n",
    "        'Function: {function_string}'\n",
    "        'Error: {error_description}'\n",
    "        'Your response must be a comprehensive string including only crucial information on the bug report'\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
    "    bug_report = llm.invoke([message]).content.strip()\n",
    "\n",
    "    state.bug_report = bug_report\n",
    "    return state\n",
    "\n",
    "\n",
    "def memory_search_node(state: State):\n",
    "    ''' Find memories relevant to the current bug report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'Given the following bug report and existing memories, identify which memories are relevant and need updating:'\n",
    "        'Bug Report: {bug_report}'\n",
    "        'Existing Memories: {memories}'\n",
    "        'The response should be a list of integers representing memory indexes to be updated'\n",
    "        'Response Format: [memory_index, ... , memory_index]'\n",
    "        'Your response must not contain any additional text.'\n",
    "        \n",
    "    )\n",
    "    \n",
    "    message = HumanMessage(content=prompt.format(\n",
    "        bug_report=state.bug_report,\n",
    "        memories=state.memories\n",
    "    ))\n",
    "    \n",
    "    response = llm.invoke([message]).content.strip()\n",
    "    memory_indexes_to_update = json.loads(response)\n",
    "    state.memory_indexes_to_update = memory_indexes_to_update\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def memory_generation_node(state: State):\n",
    "    ''' Generate relevant memories based on new bug report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with archiving a bug report for a Python function that raised an error.'\n",
    "        'Bug Report: {bug_report}.'\n",
    "        'Your response must be a concise string including only crucial information on the bug report for future reference.'\n",
    "        'Format: # function_name ## error_description ### error_analysis'\n",
    "    )\n",
    "    \n",
    "    message = HumanMessage(content=prompt.format(\n",
    "        bug_report=state.bug_report,\n",
    "    ))\n",
    "    \n",
    "    response = llm.invoke([message]).content.strip()\n",
    "    \n",
    "    state.memories.append(response)\n",
    "        \n",
    "    return state\n",
    "\n",
    "\n",
    "def memory_modification_node(state: State):\n",
    "    ''' Modify relevant memories based on new interaction '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'Update the following memories based on the new interaction:'\n",
    "        'Bug Report: {bug_report}'\n",
    "        'Memory to Update: {memory_to_update}'\n",
    "        'Response Format: # memory_label ## updated_memory_content ### updated_memory_context'\n",
    "    )\n",
    "    memory_to_update_index = state.memory_indexes_to_update.pop(0)\n",
    "    memory_to_update = state.memories[memory_to_update_index]\n",
    "    message = HumanMessage(content=prompt.format(\n",
    "        bug_report=state.bug_report,\n",
    "        memory_to_update=memory_to_update,\n",
    "    ))\n",
    "    \n",
    "    response = llm.invoke([message]).content.strip()\n",
    "    \n",
    "    state.memories[memory_to_update_index] = response\n",
    "        \n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe049c-efda-4cc9-aa81-44b8fc534434",
   "metadata": {},
   "source": [
    "## Define Edge Functions\n",
    "Now we'll define the conditional edge function that our agent will use to control the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "898b3b42-9475-45d1-b517-26a889ff6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_router(state: State):\n",
    "    if state.error:\n",
    "        print('Error in code')\n",
    "        return 'bug_report_node'\n",
    "    else:\n",
    "        print('Code is healthy')\n",
    "        return END\n",
    "\n",
    "\n",
    "def modification_router(state: State):\n",
    "    if state.memory_indexes_to_update:\n",
    "        return 'memory_modification_node'\n",
    "    else:\n",
    "        return 'memory_generation_node'\n",
    "\n",
    "\n",
    "def update_memory(state: State):\n",
    "    if state.memory_indexes_to_update:\n",
    "        return 'memory_modification_node'\n",
    "    else:\n",
    "        return 'update_code'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4075e-b6f4-4410-a7ec-8405000984d1",
   "metadata": {},
   "source": [
    "## Build Workflow\n",
    "Now we'll create our workflow and compile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3fafb0c-8e75-4b1c-99d0-64978b40a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes to the graph\n",
    "builder.add_node('run_code', run_code)\n",
    "builder.add_node('update_code', update_code)\n",
    "builder.add_node('fix_code', fix_code)\n",
    "builder.add_node('bug_report_node', bug_report_node)\n",
    "builder.add_node('memory_search_node', memory_search_node)\n",
    "builder.add_node('memory_modification_node', memory_modification_node)\n",
    "builder.add_node('memory_generation_node', memory_generation_node)\n",
    "\n",
    "\n",
    "# Add edges to the graph\n",
    "builder.set_entry_point('run_code')\n",
    "builder.add_conditional_edges('run_code', error_router)\n",
    "builder.add_edge('bug_report_node', 'memory_search_node')\n",
    "builder.add_conditional_edges('memory_search_node', modification_router)\n",
    "builder.add_edge('memory_generation_node', 'update_code')\n",
    "builder.add_conditional_edges('memory_modification_node', update_memory)\n",
    "\n",
    "builder.add_edge('update_code', 'fix_code')\n",
    "builder.add_edge('fix_code', 'run_code')\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fec8a-1b6d-4f2a-8d49-b31ba55122dc",
   "metadata": {},
   "source": [
    "# Main Function\n",
    "Define the function that runs the instanciates the workflow and its state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465b71e0-3aca-4e66-a240-5886b29792fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_self_healing_code_system(function, arguments):\n",
    "\n",
    "    state = State(\n",
    "        error=False,\n",
    "        function=function,\n",
    "        function_string=inspect.getsource(function),\n",
    "        arguments=arguments,\n",
    "    )\n",
    "    \n",
    "    for output in graph.stream(state):\n",
    "        last_state = output\n",
    "        pass\n",
    "\n",
    "    return last_state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc740e-322a-444f-8140-8e72b2c71160",
   "metadata": {},
   "source": [
    "# Run Program\n",
    "Instanciate the main function and observe outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b19f3af-cc4c-4201-bc3b-15588c112ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in code\n",
      "Code is healthy\n",
      "Error in code\n",
      "Code is healthy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'run_code': {'function': <function divide_two_numbers(a, b)>,\n",
       "  'function_string': 'def divide_two_numbers(a, b):\\n    return a/b\\n',\n",
       "  'arguments': ['a', 0],\n",
       "  'error': False,\n",
       "  'error_description': \"unsupported operand type(s) for /: 'str' and 'int'\",\n",
       "  'new_function_string': 'def divide_two_numbers(a, b):\\n    if isinstance(a, str) or isinstance(b, str):\\n        return \"Error: both arguments must be numbers.\"\\n    return a / b',\n",
       "  'bug_report': '**Bug Report**\\n\\n**Title:** TypeError in `divide_two_numbers` function\\n\\n**Function:** `divide_two_numbers(a, b)`\\n\\n**Error Message:** `unsupported operand type(s) for /: \\'str\\' and \\'int\\'`\\n\\n**Description:** The function raises a TypeError when the first argument `a` is of type `str` and the second argument `b` is of type `int`. The division operation does not support these operand types.\\n\\n**Steps to Reproduce:**\\n1. Call the function with a string as the first argument and an integer as the second argument, e.g., `divide_two_numbers(\"10\", 2)`.\\n\\n**Expected Behavior:** The function should either handle the input types gracefully (e.g., convert the string to a float or int) or raise a more descriptive error message.\\n\\n**Actual Behavior:** The function raises a TypeError indicating incompatible operand types for the division operation.\\n\\n**Suggested Fix:** Implement input type validation to ensure both `a` and `b` are numeric types (int or float) before performing the division.',\n",
       "  'memories': [\"# divide_two_numbers  \\n## TypeError: unsupported operand type(s) for /: 'str' and 'int'  \\n### Function raises TypeError when first argument is a string and second is an integer; input type validation needed.\"],\n",
       "  'memory_indexes_to_update': []}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sample function to heal\n",
    "def divide_two_numbers(a, b):\n",
    "    return a/b\n",
    "\n",
    "run_self_healing_code_system(divide_two_numbers, [10, 0])\n",
    "run_self_healing_code_system(divide_two_numbers, ['a', 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
